# Einf√ºhrung in k√ºnstliche Intelligenz und Machine Learning

Das Hauptziel dieser Veranstaltung ist **üí™ENABLINGüí™**. D.h. Sie sollen am Ende des Semesters etwas m√∂glicherweise/hoffentlich n√ºtzliches k√∂nnen. Um dieses Ziel in der knappen zur Verf√ºgung stehenden Zeit zu erreichen, werden Sie an der ein oder anderen Stelle ins kalte Wasser geworfen ‚Äî schwimmen üèä‚Äç‚ôÄÔ∏è Sie los!

In Bezug auf maschinelles Lernen brauchen wir, um etwas n√ºtzliches bewerkstelligen zu k√∂nnen insbesondere
- ein paar grundlegende √úberlegungen zum "Lernen" an sich;
- ein paar mathematische √úberlegungen;
- eine grobe Vorstellung, wie Algorithmen funktionieren;
- ein paar grundlegende Programmierkenntnisse;
- eine benutzerfreundliche Software-Bibliothek, in der ML-Methoden professionell implementiert sind.

Um Ihre Erwartungen zu managen: Nein, Sie werden in diesem Kurs in keinem der genannten Gebiete Profis! Nein, wir legen nirgends ein solides Fundament, auf das man m√ºhelos beliebig hoch aufbauen kann. Aber: Sie lernen alles um direkt loslegen zu k√∂nnen üòé.

## Literatur
Im Rahmen dieser Veranstaltung empfehle ich insbesondere folgende Werke:
- G√©ron, Hands-on machine learning with Scikit-Learn & TensorFlow, O‚ÄôReilly (2022) ‚Äî [Jupyter Notebooks](https://github.com/ageron/handson-ml3) verf√ºgbar
- Goodfellow, Deep Learning (Adaptive Computation and Machine Learning), MIT Press (2016) ‚Äî DAS einf√ºhrende Standardwerk zu Deep Learning, [im Volltext verf√ºgbar](http://www.deeplearningbook.org)
- VanderPlas, Python Data Science Handbook, O'Reilly ‚Äî sehr intuitive Darstellung einiger Algorithmen, [im Volltext verf√ºgbar](https://jakevdp.github.io/PythonDataScienceHandbook/)
- Shalev-Schwartz, Ben-David, Understanding Machine Learning, Cambridge University Press, 2014 ‚Äî genaue Einf√ºhrung in die Thematik inkl. Lerntheorie und genauen Hintergr√ºnden der Algorithmen, [im Volltext verf√ºgbar](https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning)
---

<!-- ## Woche 13
Aus mehrfachen Wunsch hin findet die letzte Veranstaltung des Semesters [online](https://hm-edu.zoom.us/j/66727078430?pwd=WjMzWC9ZWStuci9hdHJ0MXkyZGxtQT09) statt. Wir betrachten eine knappe Einf√ºhrung in neuronale Netze. Die Notizen dazu finden Sie im [OneNote-Dokument][onenote]. 

Au√üerdem k√∂nnen Fragen im Umfeld der Studienarbeiten besprochen werden.

### Praktikum
[TensorFlow Playground](https://playground.tensorflow.org/) stellt eine direkt zug√§ngliche, einfache und intuitive Umgebung bereit, um mit neuronalen Netzen sehr einfach zu experimentieren. Eine Anleitung, wie Sie damit die Funktionsweise neuronaler Netze strukturiert erkunden k√∂nnen, finden Sie [hier](Praktikum/Pr9_TF_Playground.html).

---
## Woche 12
Diese Woche betrachten wir nach PCA ein weiteres Verfahren der Klasse *unsupervised*. Konkret geht es darum, vorliegende Daten in Cluster aufzuteilen. Ein intuitiv sehr gut zug√§ngliches Verfahren (wir hatten es zu Beginn des Semesters schon mal kurz angerissen) ist [k-Means](Vorlesung/04.06_k-Means_GMM.ipynb). Einen sehr guten √úberblick √ºber die prinzipiellen Probleme der Aufgabenstellen *Clustern* finden Sie in Kap. 22 von *Understanding Machine Learning*. Auch der Zusammenhang zu graphentheoretischen Problemen wird dort deutlich gemacht.
Um gewisse Probleme von k-Means zu umgehen, betrachten wir au√üerdem noch sog. Gaussian Mixture Models (GMMs). 

### Praktikum
Diese Woche gibt es keine neue Praktikumsaufgabe. Stattdessen findet wie angek√ºndigt die Pr√§sentation einer Projektarbeit statt, bei der vier Studenten einen automatischen Logger entwickelt haben, der mit einer Kamera Messinstrumente ablie√üt, diese durch ML-Methoden interpretiert und protokolliert.
Auch auf m√∂gliche Fragen zu den Themen der Studienarbeit werden wir eingehen.

---

## Woche 11
**WICHTIG:** Diese Woche findet **keine** Pr√§senzveranstaltung statt.

Ich bitte Sie, das Thema [Principal Component Analysis (PCA)](Vorlesung/04.05_PCA.ipynb) anhand des Notebooks und des darin verlinkten Videos zu erarbeiten. Anschlie√üend stehe ich Ihnen ab 11:45 Uhr via [Zoom](https://hm-edu.zoom.us/j/69101999484?pwd=RkZFWU5Ic1l6U3VINEpvZmxMZGhuQT09) f√ºr Fragen bzw. zur Diskussion des Themas zur Verf√ºgung.

### Praktikum
Auf mehrfache Anregung hin stelle ich Ihnen diese Woche Zeit zur Verf√ºgung, um das zugegebenerma√üen sehr umfangreiche [Praktikum 7 (End-to-end ML project)](Praktikum/Pr7_End_to_end_ML_project.ipynb) weiter zu bearbeiten. Dies ist eine optimale Vorbereitung f√ºr die Studienarbeit, deren Themen n√§chste Woche gestellt werden.

---

## Woche 10
Wir erg√§nzen das Beispiel "Gesichtserkennung" zu den SVMs.
Danach besprechen wir [Entscheidungsb√§ume](Vorlesung/04.04_Random_Forests.ipynb) (*Decision Trees*) und darauf aufbauend - anhand des *Bagging* Prinzips - die sog. *Random Forests*. In diesem Zusammenhang betrachten wir sowohl Klassifizierungs- als auch Regressionsprobleme.

### Praktikum
Im Praktikum versuchen wir uns anhand der ber√ºhmten [MNIST-Daten](http://yann.lecun.com/exdb/mnist/) eine Multiclass-Klassifizierung zu meistern. Wir erstellen dazu ein Ensemble von verschiedenen Methoden und verwenden Hard- und Soft-Voting. Damit werden wir einen Genauigkeit von knapp 97% erzielen k√∂nnen.
- [Aufgabenstellung](Praktikum/Pr8_MNIST_blank.ipynb)
- [L√∂sungsvorschlag](Praktikum/Pr8_MNIST_sol.ipynb)

---
--- -->

## Woche 9
Wir besprechen den Rest der Notebooks zu [linearen Modellen](Vorlesung/04.02_Lineare_Modelle.ipynb), insbesondere das Thema Klassifizierung.
Danach besch√§ftigen wir uns mit [Support Vector Machines](Vorlesung/04.03_SVM.ipynb) und beleuchten knapp das Konzept der Datenanreicherung bzw. den "Kernel-Trick".

### Praktkikum
In dieser Session sollen Sie die M√∂glichkeit bekommen, ein komplettes Machine Learning Projekt von Anfang bis Ende durchzuf√ºhren. Dazu verwenden wir das sehr gut beschriebene Beispiel einer Regressionsanalyse von Immobilienpreisen aus dem Buch *Hands-on machine learning with Scikit-Learn, Keras & TensorFlow von A. G√©ron*. Eine Kopie eines Gro√üteils des *Chapter 2 ‚Äì End-to-end Machine Learning project* finden Sie bei [hier](Praktikum/Geron%20-%20Hands-on-ML%20chap_2.pdf). 
Ziel ist es, dass Sie dieses Projekt durcharbeiten/nachvollziehen um sich speziell auf Ihr eigenes Projekt im Rahmen der Studienarbeit vorzubereiten bzw. um daf√ºr eine weitere Referenz zu haben.
- [Beschreibung: Chapter 2 ‚Äì End-to-end Machine Learning project](Praktikum/Geron%20-%20Hands-on-ML%20chap_2.pdf)
- [Zugeh√∂riges Jupyter Notebook](Praktikum/Pr7_End_to_end_ML_project.ipynb)
---

## Woche 8
Wir besprechen [lineare Modelle](Vorlesung/04.02_Lineare_Modelle.ipynb) allgemein und erl√§utern daran verschiedene M√∂glichkeiten zur Regularisierung. Konkret betrachten wir *Ridge* und *Lasso*, d.h. die $`L_2`$ und $`L_1`$ Regularisierung. Au√üerdem betrachten wir, wie Multi-Class Klassifizierung funktioniert.

### Praktikum
Wir setzen das Praktikum der letzen Woche fort. Zuerst versuchen wir, die vorliegenden Daten besser zu treffen. Im zweiten Teil erstellen wir ein Vorhersagemodell, welches basierend auf historischen Daten den Fahrradverkehr auf der Fremont Bridge vorhersagen kann.
- [Aufgabenstellung](Praktikum/Pr6_Lineare_Modelle_blank.ipynb)
- [L√∂sungsvorschlag](Praktikum/Pr5_6_Lineare_Modelle_sol.ipynb)
---

## Woche 7
Wir besprechen detaillierter die Klasse der [Naive Bayes Modelle](Vorlesung/04.01_Naive_Bayes.ipynb).

Diese Woche kann aufgrund eines Berufungsverfahrens leider *kein* Praktikum mit Betreuung in Pr√§senz stattfinden. Bitte erarbeiten Sie die Aufgabe zu Linearen Modellen eigenst√§ndig. Wir werden n√§chste Woche darauf aufbauen.


### Praktikum
Wir bauen ein (lineares) Modell, dass den Fahrradverkehr √ºber die [Fremont Bridge in Seattle](https://en.wikipedia.org/wiki/Fremont_Bridge_(Seattle)) modelliert. Datenaufbereitung, Erzeugung von Features und Hinzuf√ºgen weiterer Daten stehen hier im Mittelpunkt.
- [Aufgabenstellung](Praktikum/Pr5_Lineare_Modelle_blank.ipynb)
- [L√∂sungsvorschlag](Praktikum/Pr5_Lineare_Modelle_sol.ipynb)
---

## Woche 6
Wir besprechen das wichtige Thema *Feature Engineering*. Damit ist gemeint, dass aus vorliegenden Daten erst einmal Features abgeleitet werden, bevor diese dann als Input f√ºr ML-Modelle verwendet werden k√∂nnen. Dies ist offensichtlich n√∂tig, wenn der Input z.B. aus kategorischen Daten oder aus Text besteht, siehe [Notebook](Vorlesung/03.03_Feature_Eng.ipynb). Allerdings ist es h√§ufig auch sinnvoll, aus vorliegenden Daten neue Features zu generieren, siehe Abschnitt "Abgeleitete Features".

### Praktikum
Im Praktikum behandeln wir die in der Machine Learning Welt sehr popul√§re "Titanic-Challenge". Aus den Personendaten der einzelnen Passagiere der Titanic soll vorhergesagt werden, wer die Schiffskatastrophe √ºberlebt:
- [Aufgabenstellung](Praktikum/Pr4_Titanic_blank.ipynb)
- [L√∂sungsvorschlag](Praktikum/Pr4_Titanic_sol.ipynb)
---
## Woche 5
**Diese Woche keine Pr√§senzveranstaltung. Bitte erarbeiten Sie die Notebooks selbstst√§ndig bzw. anhand der darin verlinkten Videos.**

Wir f√ºhren die √úberlegungen zur Modellwahl von letzter Woche fort. 
Eine mit der Modellbewertung eng verwandte Fragestellung ist die der Modellwahl: *Wenn die Performance des Modells nicht befriedigend ist, was kann unternommen werden?*
Prinzipiell kann ein komplexeres (oder ein weniger komplexes) Modell verwendet werden und es k√∂nnen mehr (oder weniger) Daten eingesetzt werden. Die weitere (und sehr wichtige) M√∂glichkeit, andere Features zu verwenden, klammern wir f√ºr die Betrachtung diese Woche noch aus.

Insbesondere betrachten wir die Abh√§ngigkeit der Modellperformance von der  Kapazit√§t des Modells durch sog. Validierungskurven. Anschlie√üend untersuchen wir die Auswirkung der Menge der Trainingsdaten mit Hilfe von Trainingskurven, siehe [Notebook](Vorlesung/03.02_Modellwahl.ipynb).


### Praktikum
Im Praktikum behandeln wir Cross Validation, um f√ºr unterschiedliche Modell die optimalen Hyperparameter zu bestimmen:
- [Aufgabenstellung](Praktikum/Pr3_CrossVal_GridSearch_blank.ipynb)
- [L√∂sungsvorschlag](Praktikum/Pr3_CrossVal_GridSearch_sol.ipynb)

---

## Woche 4
Wir untersuchen die Frage, welche Fehler bei einem ML Model relevant sind und wie Modelle bewertet werden k√∂nnen, siehe [OneNote][onenote] Kapitel 3 und 3.1. Diese √úberlungen zur Modellbewertung vertiefen wir durch eine konkrete Anwendung auf das Iris-Beispiel, siehe [Notebook](Vorlesung/03.01_Accuracy.ipynb).


### Praktikum
Im Praktikum geht es um die Erkennung handschriftlicher Ziffern. Die Daten sollen mithilfe von Dimensionsreduktion zuerst untersucht werden, um ein Gef√ºhl daf√ºr zu bekommen, wie kompliziert eine derartige Klassifizierungsaufgabe wohl ist. Zur Modellvalidierung soll Cross Validation verwendet werden. Als Zusatz wird der Aspekt der "Stratification", also der "statistischen Ausbalancierung" angesprochen.

- [Aufgabenstellung](Praktikum/Pr2_handwritten_digits_blank.ipynb)
- [L√∂sungsvorschlag](Praktikum/Pr2_handwritten_digits_sol.ipynb) 
---

## Woche 3
**Diese Woche nutzen wir f√ºr die Pr√§senzveranstaltungen den zweiten und dritten Slot.**

Konkret:
- Vorlesung 11:45 - 13:15 Uhr
- Praktikum 13:30 - 15:00 Uhr

Diese Woche beginne wir die Arbeit mit der Estimator API von Scikit-Learn:
- Das Prinzip ist knapp im [OneNote Notebook][onenote] dargestellt, als erstes Beispiel f√ºr die systematische Anwendung der API im Rahmen einer *supervised learning* Aufgabe betrachten wir eine [einfache lineare Regression](Vorlesung/02.02_API_supervised.ipynb).
- Au√üerdem betrachten wir ein Beispiel zu *unsupervised learning*:
Wir wollen die Iris-Daten clustern, sprich die vorhandenen Daten in drei Gruppen aufteilen, ohne dass wir spezifizieren, wie diese Gruppen ("Cluster") aussehen. Bevor wir das machen, wollen wir erst einmal einen Eindruck bekommen, ob ein solches Clustering √ºberhaupt vielversprechend ist, d.h. ob wir erwarten d√ºrfen, dass die erzeugten Cluster mit den real vorliegenden unterschiedlichen Spezies √ºbereinstimmen. Dazu f√ºhren wir eine Dimensionsreduktion mittels PCA ("Principal Component Analysis", Details in einer sp√§teren Vorlesung) durch, die urspr√ºnglich vierdimensionalen Iris-Daten sollen auf die wesentlichen zwei Dimensionen reduziert werden. Die so aufbereiteten Daten k√∂nnen wir dann visuell untersuchen. Dieses Beispiel finden Sie in [diesem Notebook](Vorlesung/02.03_API_unsupervised.ipynb). 
 

 
### Praktikum
Im Praktikum werden diese Inhalte anhand verschiedener Clustering-Algorithmen u.a. am Beispiel der Iris-Daten vertieft. Die Aufgabenstellung des Praktikums finden Sie (inkl. Erl√§uterung per Video) in unten stehendem Notebook. Auch einen L√∂sungsvorschlag (inkl. Erl√§uterung per Video) finden Sie unten.
- [Aufgabenstellung](Praktikum/Pr1_Clustering_blank.ipynb)
- [L√∂sungsvorschlag](Praktikum/Pr1_Clustering_sol.ipynb) 
 
**Somit k√∂nnen Sie auch das Praktikum ggf. rein online absolvieren (hier bietet es sich vielleicht noch mehr an als beim Vorlesungsteil).**

Ich rate Ihnen, wirklich zu versuchen, die Aufgaben zu l√∂sen OHNE in den L√∂sungsvorschlag zu schauen. Nutzen Sie gerne alle anderen verf√ºgbaren Quellen, insbesondere auch die Suchmaschine Ihrer Wahl und die [Scikit-Learn Dokumentation][sklearn_user_guide]. So lernen Sie, mit immer verf√ºgbaren Quellen Aufgaben zu l√∂sen - das ist aus meiner Sicht ein wesentliches Ziel der Veranstaltung!

---
## Woche 2
Diese Woche betrachten wir 
- ein erstes Beispiel, welches gem. der Definition von Mitchell (vgl. erste Vorlesung) als "maschinelles Lernen" bezeichnet werden kann: die **lineare Regression**. Wir begr√ºnden, warum lineare Regression eine (einfache) Methode des maschinellen Lernens ist und betrachten ein ganz [konkretes Beispiel](Vorlesung/01_lin_reg.ipynb).
- die strukturierte [Darstellung von Daten](Vorlesung/02.01_Ausgangspunkt_Daten.ipynb). Wir stellen insbesondere √úberlegungen an zur grafischen Darstellung von Daten und warum das so wichtig ist.
- das Software-Tool, welches wir f√ºr die Veranstaltung nutzen werden: [Scikit-Learn](https://scikit-learn.org/)  

Um Scikit-Learn nutzen zu k√∂nnen, k√∂nnen Sie (u.a.)
- die kostenfreie Cloudplattform [Google Colab](https://colab.research.google.com/) verwenden;
- Python und Scikit-Learn lokal auf Ihrem Rechner installieren. Eine einfache M√∂glichkeit ist die Installation von [Anaconda](https://www.anaconda.com/), als Editor bzw. IDE empfehle ich [VSCode](https://code.visualstudio.com/).

F√ºr den leichten und problemfreien Einstieg rate ich zur ersten Option.


Im Praktikum gebe ich au√üerdem einen Crash-Kurs in Python. Im Rahmen dessen werde ich auch Googles Cloud-Computing Umgebung [Colab](https://colab.research.google.com/) kurz pr√§sentieren. Das entsprechende [Jupyter Notebook](Tutorials/python_tutorial.ipynb) stammt aus dem Kurs [CS231n](http://cs231n.stanford.edu/).

## Woche 1
In der Einf√ºhrung besprechen wir:
- Verh√§ltnis verschiedener relevanter Begriffe zueinander
- Was ist "Lernen"?
- Definition(en) vom Machine Learning
- Wann ist ML sinnvoll?
- Arten von ML
- ERM ("Empirical Risk Minimization") Prinzip
- Overfitting

Die entsprechenden Notizen finden Sie im [OneNote Notebook][onenote].

‚ùó Um insbesondere die Themen ERM und Overfitting zu vertiefen und ein Gef√ºhl daf√ºr zu vermitteln, dass all diese Themen auf einem soliden mathematischen Fundament stehen, arbeiten Sie bitte Kapitel 2 "A gentle start" von [Understanding Machine Learning](https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/understanding-machine-learning-theory-algorithms.pdf) durch. Wir werden dies n√§chste Woche besprechen.   





[onenote]: https://1drv.ms/o/s!AhdJTnngugIpjTspCZMn58QtIXnt?e=TKQbVN
[sklearn_user_guide]: https://scikit-learn.org/stable/user_guide.html