# Einf√ºhrung in k√ºnstliche Intelligenz und Machine Learning

Das Hauptziel dieser Veranstaltung ist **üí™ENABLINGüí™**. D.h. Sie sollen am Ende des Semesters etwas m√∂glicherweise/hoffentlich n√ºtzliches k√∂nnen. Um dieses Ziel in der knappen zur Verf√ºgung stehenden Zeit zu erreichen, werden Sie an der ein oder anderen Stelle ins kalte Wasser geworfen ‚Äî schwimmen üèä‚Äç‚ôÄÔ∏è Sie los!

In Bezug auf maschinelles Lernen brauchen wir, um etwas n√ºtzliches bewerkstelligen zu k√∂nnen insbesondere
- ein paar grundlegende √úberlegungen zum "Lernen" an sich;
- ein paar mathematische √úberlegungen;
- eine grobe Vorstellung, wie Algorithmen funktionieren;
- ein paar grundlegende Programmierkenntnisse;
- eine benutzerfreundliche Software-Bibliothek, in der ML-Methoden professionell implementiert sind.

Um Ihre Erwartungen zu managen: Nein, Sie werden in diesem Kurs in keinem der genannten Gebiete Profis! Nein, wir legen nirgends ein solides Fundament, auf das man m√ºhelos beliebig hoch aufbauen kann. Aber: Sie lernen alles um direkt loslegen zu k√∂nnen üòé.

## Literatur
Im Rahmen dieser Veranstaltung empfehle ich insbesondere folgende Werke:
- G√©ron, Hands-on machine learning with Scikit-Learn & TensorFlow, O‚ÄôReilly (2022) ‚Äî [Jupyter Notebooks](https://github.com/ageron/handson-ml3) verf√ºgbar
- Goodfellow, Deep Learning (Adaptive Computation and Machine Learning), MIT Press (2016) ‚Äî DAS einf√ºhrende Standardwerk zu Deep Learning, [im Volltext verf√ºgbar](http://www.deeplearningbook.org)
- VanderPlas, Python Data Science Handbook, O'Reilly ‚Äî sehr intuitive Darstellung einiger Algorithmen, [im Volltext verf√ºgbar](https://jakevdp.github.io/PythonDataScienceHandbook/)
- Shalev-Schwartz, Ben-David, Understanding Machine Learning, Cambridge University Press, 2014 ‚Äî genaue Einf√ºhrung in die Thematik inkl. Lerntheorie und genauen Hintergr√ºnden der Algorithmen, [im Volltext verf√ºgbar](https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning)

## Woche 1
In der Einf√ºhrung besprechen wir:
- Verh√§ltnis verschiedener relevanter Begriffe zueinander
- Was ist "Lernen"?
- Definition(en) vom Machine Learning
- Wann ist ML sinnvoll?
- Arten von ML
- ERM ("Empirical Risk Minimization") Prinzip
- Overfitting

Die entsprechenden Notizen finden Sie im [OneNote Notebook][onenote].

‚ùó Um insbesondere die Themen ERM und Overfitting zu vertiefen und ein Gef√ºhl daf√ºr zu vermitteln, dass all diese Themen auf einem soliden mathematischen Fundament stehen, arbeiten Sie bitte Kapitel 2 "A gentle start" von [Understanding Machine Learning](https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/understanding-machine-learning-theory-algorithms.pdf) durch. Wir werden dies n√§chste Woche besprechen.   

Im Praktikum gebe ich au√üerdem einen Crash-Kurs in Python. Im Rahmen dessen werde ich auch Googles Cloud-Computing Umgebung [Colab](https://colab.research.google.com/) kurz pr√§sentieren. Das entsprechende [Jupyter Notebook](Tutorials/python_tutorial.ipynb) stammt aus dem Kurs [CS231n](http://cs231n.stanford.edu/).

## Woche 2
Diese Woche betrachten wir 
- ein erstes Beispiel, welches gem. der Definition von Mitchell (vgl. erste Vorlesung) als "maschinelles Lernen" bezeichnet werden kann: die **lineare Regression**. Wir begr√ºnden, warum lineare Regression eine (einfache) Methode des maschinellen Lernens ist und betrachten ein ganz [konkretes Beispiel](Vorlesung/01_lin_reg.ipynb).
- die strukturierte [Darstellung von Daten](Vorlesung/02.01_Ausgangspunkt_Daten.ipynb). Wir stellen insbesondere √úberlegungen an zur grafischen Darstellung von Daten und warum das so wichtig ist.
- das Software-Tool, welches wir f√ºr die Veranstaltung nutzen werden: [Scikit-Learn](https://scikit-learn.org/)
Wir betrachten, wie Daten typischerweise dargestellt werden und sprechen die wesentlichen Elemente der Estimator API durch. Das Prinzip ist knapp im [OneNote Notebook][onenote] dargestellt, als erstes Beispiel f√ºr die systematische Anwendung der API im Rahmen einer *supervised learning* Aufgabe betrachten wir eine [einfache lineare Regression](Vorlesung/02.02_API_supervised.ipynb).

Um Scikit-Learn nutzen zu k√∂nnen, k√∂nnen Sie (u.a.)
- die kostenfreie Cloudplattform [Google Colab](https://colab.research.google.com/) verwenden;
- Python und Scikit-Learn lokal auf Ihrem Rechner installieren. Eine einfache M√∂glichkeit ist die Installation von [Anaconda](https://www.anaconda.com/), als Editor bzw. IDE empfehle ich [VSCode](https://code.visualstudio.com/).
F√ºr den leichten und problemfreien Einstieg rate ich zur ersten Option.


Um f√ºr dieses umfangreiche Programm ausreichend Zeit zu haben, werden wir auch einen Teil der Praktikumsstunde ab 11:45 Uhr nutzen. Ein Praktikum im eigentlichen Sinne findet aber diese Woche noch nicht statt. Alle Inhalte finden Sie auch online, die Videos sind im OneNote verlinkt.

## Woche 3
Diese Woche arbeiten wir weiter mit der Estimator API von Scikit-Learn, konkret betrachten wir ein noch ausstehendes Beispiel zu *unsupervised learning*:

Wir wollen die Iris-Daten clustern, sprich die vorhandenen Daten in drei Gruppen aufteilen, ohne dass wir spezifizieren, wie diese Gruppen ("Cluster") aussehen. Bevor wir das machen, wollen wir erst einmal einen Eindruck bekommen, ob ein solches Clustering √ºberhaupt vielversprechend ist, d.h. ob wir erwarten d√ºrfen, dass die erzeugten Cluster mit den real vorliegenden unterschiedlichen Spezies √ºbereinstimmen. Dazu f√ºhren wir eine Dimensionsreduktion mittels PCA ("Principal Component Analysis", Details in einer sp√§teren Vorlesung) durch, die urspr√ºnglich vierdimensionalen Iris-Daten sollen auf die wesentlichen zwei Dimensionen reduziert werden. Die so aufbereiteten Daten k√∂nnen wir dann visuell untersuchen. Dieses Beispiel finden Sie in [diesem Notebook](Vorlesung/02.03_API_unsupervised.ipynb). 
 

Wir untersuchen auch die Frage, welche Fehler bei einem ML Model relevant sind und wie Modelle bewertet werden k√∂nnen, siehe [OneNote][onenote] Kapitel 3 und 3.1. Diese √úberlegungen setzen wir dann wieder im Iris-Beispiel um, siehe [Notebook](Vorlesung/03.01_Accuracy.ipynb).
 
### Praktikum
Im Praktikum werden diese Inhalte anhand verschiedener Clustering-Algorithmen u.a. am Beispiel der Iris-Daten vertieft. Die Aufgabenstellung des Praktikums finden Sie (inkl. Erl√§uterung per Video) in unten stehendem Notebook. Auch einen L√∂sungsvorschlag (inkl. Erl√§uterung per Video) finden Sie unten.
- [Aufgabenstellung](Praktikum/Pr1_Clustering_blank.ipynb)
- [L√∂sungsvorschlag](Praktikum/Pr1_Clustering_sol.ipynb) 
 
**Somit k√∂nnen Sie auch das Praktikum ggf. rein online absolvieren (hier bietet es sich vielleicht noch mehr an als beim Vorlesungsteil).**

Ich rate Ihnen, wirklich zu versuchen, die Aufgaben zu l√∂sen OHNE in den L√∂sungsvorschlag zu schauen. Nutzen Sie gerne alle anderen verf√ºgbaren Quellen, insbesondere auch die Suchmaschine Ihrer Wahl und die [Scikit-Learn Dokumentation][sklearn_user_guide]. So lernen Sie, mit immer verf√ºgbaren Quellen Aufgaben zu l√∂sen - das ist aus meiner Sicht ein wesentliches Ziel der Veranstaltung!


[onenote]: https://1drv.ms/u/s!AhdJTnngugIpjTsnJWCmXJsxpBf3?e=6de34K
[sklearn_user_guide]: https://scikit-learn.org/stable/user_guide.html