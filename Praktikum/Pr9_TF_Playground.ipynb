{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3R0FGxq-SnyX"
   },
   "source": [
    "# Praktikum Session 9: Verhalten neuronaler Netze\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mva2dgt5Tvlr"
   },
   "source": [
    "Auf [TensorFlow Playground](https://playground.tensorflow.org) können kleinere neuronale Netze interaktiv visuell erkundet werden. Dabei können auf sehr einfache Weise Netze mit bis zu sechs Hidden Layers mit jeweils bis zu acht Neuronen erstellt und verwendet werden.\n",
    "\n",
    "Dieses intuitive Tool wollen wir in dieser Session verwenden, um ein Gefühl für die Funtkionsweise neuronaler Netze zu bekommen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MhYW0MwKUl1m"
   },
   "source": [
    "## 1. Klassifizierung\n",
    "Unter Klassifierung versteht man das Problem, dass einem gegebenen Datenpunkt eine (diskrete) Klasse zugeordnet werden soll.\n",
    "\n",
    "Zum Beispiel:\n",
    "\n",
    "| Input Daten           | Mögliche Klassen   |\n",
    "|-----------------------|--------------------|\n",
    "| Foto von einem Objekt | Mensch; Auto; Baum |\n",
    "| E-Mail                | Spam; kein Spam    |\n",
    "| 2d Punkt              | Orange oder blaue Kategorie |\n",
    "\n",
    "Wir möchten eine einfache binäre Klassifizierung (d.h. es gibt zwei Klassen) von zweidimensionalen Punkten vornehmen. Dazu soll ein neuronales Netz auf Trainingsdaten trainiert und anschließend auf Testdaten getestet werden. Die zu unterscheidenden Daten sind im ersten Fall recht einfach strukturiert und sollten daher leicht zu klassifizieren sein."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q7O88H29etEZ"
   },
   "source": [
    "### 1.1 Einfach zu trennende Daten\n",
    "Öffnen Sie [diese](https://playground.tensorflow.org/#activation=linear&batchSize=1&dataset=gauss&regDataset=reg-plane&learningRate=0.0001&regularizationRate=0&noise=5&networkShape=1&seed=0.44087&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false&showTestData_hide=false&activation_hide=true&problem_hide=true&noise_hide=true&discretize_hide=true&regularization_hide=true&dataset_hide=true&batchSize_hide=true&playButton_hide=true&regularizationRate_hide=true&percTrainData_hide=false&numHiddenLayers_hide=true) Version von TensorFlow Playgroud und experimentieren Sie. Links oben können Sie jeweils einen Trainingsschritt (\"Epoch\") durchführen bzw. das Netz auf einen untrainierten Anfangszustand zurücksetzen.\n",
    "\n",
    "Machen Sie sich klar, was \"Test loss\" und \"Training loss\" (rechts oben) bedeutet.\n",
    "\n",
    "Untersuchen Sie, wie sich das Verhalten des Netzes ändert, wenn Sie:\n",
    "- Die Lernrate (\"learning rate\", rechts oben) ändern;\n",
    "- Die Gewichte des Ausgangsnetzes ändern (auf die Verbindung zwischen Input- und Outputneuron klicken und Wert eingeben).\n",
    "\n",
    "Ist es sinnvoll, weitere Neuronen hinzuzufügen (Klick auf das Plus über dem Output-Layer)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dfnon9mQjthP"
   },
   "source": [
    "### 1.2 Linear nicht trennbare Daten (XOR)\n",
    "Öffnen Sie [diese](https://playground.tensorflow.org/#activation=linear&batchSize=1&dataset=xor&regDataset=reg-plane&learningRate=0.0001&regularizationRate=0&noise=5&networkShape=1&seed=0.57090&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false&showTestData_hide=false&activation_hide=false&problem_hide=true&noise_hide=true&discretize_hide=true&regularization_hide=true&dataset_hide=true&batchSize_hide=true&playButton_hide=false&regularizationRate_hide=true&percTrainData_hide=false&numHiddenLayers_hide=true) Version von TensorFlow Playground und versuchen Sie, eine gute Klassifizierung zu erreichen. Verwenden Sie in dieser Übung nur die Features $x_1$ und $x_2$.\n",
    "Links oben ist nun ein \"Play-Button\" verfügbar, der es erlaubt, die Epochen automatisch ablaufen zu lassen.\n",
    "\n",
    "**A1:** Versuchen Sie die Anzahl der Neuronen im Hidden Layer von 1 auf 2 zu erhöhen. Versuchen Sie auch, eine nicht-lineare Aktivierungsfunktion zu verwenden (rechts oben) wie z.B. ReLU. Kann ein solches Modell diese Daten gut lernen?\n",
    "\n",
    "**A2:** Versuchen Sie nun, die Anzahl der Neuronen von 2 auf 3 zu erhöhen und verwenden Sie die ReLU Aktivierungsfunktion.\n",
    "- Starten Sie das Training des Modells mehrmals neu. Wie verhält sich die Qualität des erzeugten Modells?\n",
    "- Ist es nun möglich, die Daten gut zu modellieren?\n",
    "- Warum? *Hinweis: Betrachten Sie insbesondere, wie sich die Neuronen im Hidden Layer verhalten.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r9Gwk2UXnYIv"
   },
   "source": [
    "### 1.3 XOR mit tieferen Netzen\n",
    "Verwenden Sie nun [diese](https://playground.tensorflow.org/#activation=linear&batchSize=1&dataset=xor&regDataset=reg-plane&learningRate=0.01&regularizationRate=0&noise=5&networkShape=1&seed=0.57090&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false&showTestData_hide=false&activation_hide=false&problem_hide=true&noise_hide=false&discretize_hide=true&regularization_hide=true&dataset_hide=true&batchSize_hide=true&playButton_hide=false&regularizationRate_hide=true&percTrainData_hide=false&numHiddenLayers_hide=false) Version von TensorFlow Playground und experimentieren Sie damit.\n",
    "\n",
    "**A1:** Verwenden Sie ein Netz mit 2 Hidden Layers mit jeweils 2 Neuronen.\n",
    "- Beobachten Sie das Verhalten bei mehreren Neustarts (Reset links oben nicht vergessen!).\n",
    "- Kann ein solches Netz die Aufgabe lösen? \n",
    "- Warum? *Hinweis: Was ist der Input der Neuronen im zweiten Hidden Layer?*\n",
    "\n",
    "**A2:** Verwenden Sie nun im Vergleich ein Netz mit nur einem Hidden Layer, welches aber mehr als 2 Neuronen enthält.\n",
    "\n",
    "**A3:** Versuchen Sie das Problem mit einem beliebigen Netz zu lösen, welches aber im ersten Hidden Layer nur ein Neuron enthält. Was beobachten Sie? Warum?\n",
    "\n",
    "**A4:** Verwenden Sie nun ein \"großes\" Netz mit vielen Hidden Layers und vielen Neuronen pro Layer. Wie verhält sich dieses im Vergleich zu dem Netz mit einem Hidden Layer und 3 Neuronen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KS6A4EBetvI6"
   },
   "source": [
    "### 1.4. Abhängigkeit von der Initialisierung\n",
    "Verwenden Sie [diese](https://playground.tensorflow.org/#activation=relu&batchSize=10&dataset=xor&regDataset=reg-plane&learningRate=0.01&regularizationRate=0&noise=35&networkShape=3&seed=0.03711&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false&showTestData_hide=false&activation_hide=false&problem_hide=true&noise_hide=true&discretize_hide=true&regularization_hide=true&dataset_hide=true&batchSize_hide=true&playButton_hide=false&regularizationRate_hide=true&percTrainData_hide=false&numHiddenLayers_hide=false) Konfiguration und lassen Sie das Modell ca. 5 mal ca. 500 Epochen durchlaufen, damit es konvergiert. Setzen Sie das Netz nach jedem der 5 Trainings zurück (Reset Button links oben), dadurch werden die Gewichte neu zufällig initialisiert.\n",
    "\n",
    "**A1:** Vergleichen Sie die erhaltenen Ergebnisse (Form der Färbung und Fehler). \n",
    "- Was sagt das aus über die Rolle der Initialisierung?\n",
    "- Vergleichen Sie dieses Verhalten mit dem Verhalten in Aufgabe 1.1.\n",
    "\n",
    "**A2:** Verwenden Sie ein etwas komplexeres Modell, indem Sie ein weiteres Hidden Layer und ein paar Neuronen hinzufügen. Wie wirkt sich das auf die untersuchte Stabilität aus?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pn5LdHmrytfc"
   },
   "source": [
    "### 1.5 Spiralen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cHTHBUTuzHQH"
   },
   "source": [
    "Verwenden Sie [diese](https://playground.tensorflow.org/#activation=relu&batchSize=10&dataset=spiral&regDataset=reg-plane&learningRate=0.1&regularizationRate=0&noise=50&networkShape=3&seed=0.93571&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false&showTestData_hide=false&activation_hide=false&problem_hide=false&noise_hide=false&discretize_hide=false&regularization_hide=false&dataset_hide=false&batchSize_hide=false&playButton_hide=false&regularizationRate_hide=false&percTrainData_hide=false&numHiddenLayers_hide=false) Konfiguartion und versuchen Sie, ein Modell zu generieren, das die Spirale gut lernen kann.\n",
    "\n",
    "**A1:**Verwenden Sie **NUR** die Features $x_1$ und $x_2$ und versuchen Sie, ein möglichst gutes Modell zu erhalten. *Hinweis: Geben Sie dem Modell Zeit, Sie sollten mindestens 2000 Epochen laufen lassen.*\n",
    "- Verwenden Sie zunächst ein sehr großes Modell (8 Hidden Layer mit je 8 Neuronen). Was beobachten Sie?\n",
    "- Verkleinern Sie das Modell (z.B. 4 Hidden Layer mit 8-6-4-2 Neuronen). \n",
    "- Verringern Sie die Lernrate, z.B. auf 0,03.\n",
    "\n",
    "**A2:** In den Daten ist recht viel Rauschen enthalten, d.h. sie haben nur grob die Form einer Spirale. Das Modell soll aber letztendlich die Spirale lernen, denn diese ist die zugrunde liegende (jedoch verrauschte) Form. Das aktuelle Modell versucht jedoch, die gesamte vorliegende Struktur der Daten zu lernen, also auch das Rauschen. Maßnahmen, die zum Ziel haben, ein Modell dazu zu bringen, das Rauschen zu ignorieren, nennt man **Regularisierung**.\n",
    "- Verwenden Sie $L_2$-Regularisierung mit einer Regularisierungsrate von 0,003 und trainieren Sie das Netz erneut.\n",
    "\n",
    "**A3:** Verwenden Sie dieses Modell auf einem weniger verrauschten Datensatz, indem Sie den \"Noise\"-Regler links z.B. auf 15 setzen.\n",
    "\n",
    "**A4:** Verwenden Sie nun alle Features als Input.\n",
    "- Verkleinern Sie das Modell, z.B. 3 Hidden Layer mit 5-4-2 Neuronen.\n",
    "- Verkleinern Sie das Modell noch weiter und verwenden Sie nur ein Hidden Layer mit 5 Neuronen. Experimentieren Sie mit den anderen Parametern, verwenden Sie z.B. $\\tanh$ als Aktivierungsfunktion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Gdi3_GF1vUR"
   },
   "source": [
    "### 1.6 Verschiedene Aspekte von neuronalen Netzen\n",
    "Nutzen Sie nun nach Bedarf und Neugier alle auf [TensorFlow Playground](https://playground.tensorflow.org) zur Verfügung stehenden Optionen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rE-yfwuC7nrt"
   },
   "source": [
    "#### Layer und Muster:\n",
    "Wenn man die Default-Einstellungen beibehält, kann man gut beobachten, wie die Neuronen im ersten Layer einfache Formen lernen, die dann im zweiten Layer zu komplexeren Mustern zusammen gebaut werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T6H0VtVH8aAW"
   },
   "source": [
    "#### Aktivierungsfunktionen:\n",
    "Verwenden Sie statt $\\tanh$ die ReLU Funktion als Aktivierungsfunktion. Das Training läuft nun schneller ab, aber die Begrenzungen der einzelnen Bereiche sind linear (warum?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X-OT2F9Y8ulf"
   },
   "source": [
    "#### Lokale Minima:\n",
    "Verwenden Sie ein Netz mit nur einem Hidden Layer mit 3 Neuronen und trainieren Sie dieses mehrfach (zurücksetzen nicht vergessen!). Die Trainingszeiten, bis ein gutes Ergebnis herauskommt, unterscheiden sich stark und manchmal wird das Netz keine gute Lösung finden. Dann ist es in ein nicht allzu gutes lokales Minimum gelaufen (vergleiche Perceptron XOR aus der Vorlesung)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JU732eIF9cY-"
   },
   "source": [
    "#### Zu kleines Netz\n",
    "Wie oben bereits gesehen, kann ein zu kleines Netz (in diesem Fall mit nur 2 Neuronen) keine gute Lösung finden. Das Netz hat nicht genug **Kapazität**, um die Komplexität der Trainingsdaten abzubildet. Man spricht hier von **Underfitting**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sVL0Lhdf94my"
   },
   "source": [
    "#### Netz groß genug\n",
    "Verwenden Sie nun 8 Neuronen in einem einzigen Hidden Layer und trainieren Sie das Netz mehrfach. Es wird so gut wie niemals in ein lokales Minimum laufen und nahezu immer eine gute Lösung finden.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q4jf-J04-gUy"
   },
   "source": [
    "#### Tiefe Netze und verschwindende Gradienten\n",
    "Verwenden Sie ein Netz mit 4 Hidden Layern mit jeweils 8 Neuronen und trainieren Sie dieses auf die Spiralen-Daten. Das Training wird wesentlich länger dauern und oft wird es für längere Zeit kaum Verbesserung geben. Die Gewichte in den unteren Layern (also näher am Input) verändern sich wesentlich langsamer als in den oberen Layern. Dieses Phänomen kann an der grafischen Darstellung der Neuronen gut beobachtet werden. Es nennt sich **vanishing gradients**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kDIW5sl__q-h"
   },
   "source": [
    "# 2. Regression\n",
    "Bei Regression geht es darum, Daten eine kontinuierliche Größe zuzuordnen.\n",
    "\n",
    "Zum Beispiel:\n",
    "\n",
    "|Beispiel| Input Daten           | zu bestimmende Größe   |\n",
    "|------------|-----------------------|--------------------|\n",
    "|Schätzen des Mietpreises| Zimmeranzahl, Fläche, Lage, Baujahr, ... | Mietpreis |\n",
    "|Schweißverbindungen | Geometrische Parameter                | Kerbfaktor    |\n",
    "|Allgemeine Funktion | 2d Punkt              | Funktionswert an diesem Punkt |\n",
    "\n",
    "Auch hierfür können einfache Beispiele mit [TensorFlow Playground](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.45471&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=regression&initZero=false&hideText=false) durchgespielt und visuell betrachtet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BKSolSg9P3cs"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Pr01_TF_Playground.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
